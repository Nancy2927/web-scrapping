{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyPi0TBCwnqduei+X08aqVmt",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Nancy2927/web-scrapping/blob/main/part1.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 73
        },
        "id": "W2B0vzOROm1t",
        "outputId": "01bdff97-c2bc-4d83-c087-5796ba86403e"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "     <input type=\"file\" id=\"files-c9484336-af2d-4600-8943-e5f01d0593d6\" name=\"files[]\" multiple disabled\n",
              "        style=\"border:none\" />\n",
              "     <output id=\"result-c9484336-af2d-4600-8943-e5f01d0593d6\">\n",
              "      Upload widget is only available when the cell has been executed in the\n",
              "      current browser session. Please rerun this cell to enable.\n",
              "      </output>\n",
              "      <script>// Copyright 2017 Google LLC\n",
              "//\n",
              "// Licensed under the Apache License, Version 2.0 (the \"License\");\n",
              "// you may not use this file except in compliance with the License.\n",
              "// You may obtain a copy of the License at\n",
              "//\n",
              "//      http://www.apache.org/licenses/LICENSE-2.0\n",
              "//\n",
              "// Unless required by applicable law or agreed to in writing, software\n",
              "// distributed under the License is distributed on an \"AS IS\" BASIS,\n",
              "// WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
              "// See the License for the specific language governing permissions and\n",
              "// limitations under the License.\n",
              "\n",
              "/**\n",
              " * @fileoverview Helpers for google.colab Python module.\n",
              " */\n",
              "(function(scope) {\n",
              "function span(text, styleAttributes = {}) {\n",
              "  const element = document.createElement('span');\n",
              "  element.textContent = text;\n",
              "  for (const key of Object.keys(styleAttributes)) {\n",
              "    element.style[key] = styleAttributes[key];\n",
              "  }\n",
              "  return element;\n",
              "}\n",
              "\n",
              "// Max number of bytes which will be uploaded at a time.\n",
              "const MAX_PAYLOAD_SIZE = 100 * 1024;\n",
              "\n",
              "function _uploadFiles(inputId, outputId) {\n",
              "  const steps = uploadFilesStep(inputId, outputId);\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  // Cache steps on the outputElement to make it available for the next call\n",
              "  // to uploadFilesContinue from Python.\n",
              "  outputElement.steps = steps;\n",
              "\n",
              "  return _uploadFilesContinue(outputId);\n",
              "}\n",
              "\n",
              "// This is roughly an async generator (not supported in the browser yet),\n",
              "// where there are multiple asynchronous steps and the Python side is going\n",
              "// to poll for completion of each step.\n",
              "// This uses a Promise to block the python side on completion of each step,\n",
              "// then passes the result of the previous step as the input to the next step.\n",
              "function _uploadFilesContinue(outputId) {\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  const steps = outputElement.steps;\n",
              "\n",
              "  const next = steps.next(outputElement.lastPromiseValue);\n",
              "  return Promise.resolve(next.value.promise).then((value) => {\n",
              "    // Cache the last promise value to make it available to the next\n",
              "    // step of the generator.\n",
              "    outputElement.lastPromiseValue = value;\n",
              "    return next.value.response;\n",
              "  });\n",
              "}\n",
              "\n",
              "/**\n",
              " * Generator function which is called between each async step of the upload\n",
              " * process.\n",
              " * @param {string} inputId Element ID of the input file picker element.\n",
              " * @param {string} outputId Element ID of the output display.\n",
              " * @return {!Iterable<!Object>} Iterable of next steps.\n",
              " */\n",
              "function* uploadFilesStep(inputId, outputId) {\n",
              "  const inputElement = document.getElementById(inputId);\n",
              "  inputElement.disabled = false;\n",
              "\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  outputElement.innerHTML = '';\n",
              "\n",
              "  const pickedPromise = new Promise((resolve) => {\n",
              "    inputElement.addEventListener('change', (e) => {\n",
              "      resolve(e.target.files);\n",
              "    });\n",
              "  });\n",
              "\n",
              "  const cancel = document.createElement('button');\n",
              "  inputElement.parentElement.appendChild(cancel);\n",
              "  cancel.textContent = 'Cancel upload';\n",
              "  const cancelPromise = new Promise((resolve) => {\n",
              "    cancel.onclick = () => {\n",
              "      resolve(null);\n",
              "    };\n",
              "  });\n",
              "\n",
              "  // Wait for the user to pick the files.\n",
              "  const files = yield {\n",
              "    promise: Promise.race([pickedPromise, cancelPromise]),\n",
              "    response: {\n",
              "      action: 'starting',\n",
              "    }\n",
              "  };\n",
              "\n",
              "  cancel.remove();\n",
              "\n",
              "  // Disable the input element since further picks are not allowed.\n",
              "  inputElement.disabled = true;\n",
              "\n",
              "  if (!files) {\n",
              "    return {\n",
              "      response: {\n",
              "        action: 'complete',\n",
              "      }\n",
              "    };\n",
              "  }\n",
              "\n",
              "  for (const file of files) {\n",
              "    const li = document.createElement('li');\n",
              "    li.append(span(file.name, {fontWeight: 'bold'}));\n",
              "    li.append(span(\n",
              "        `(${file.type || 'n/a'}) - ${file.size} bytes, ` +\n",
              "        `last modified: ${\n",
              "            file.lastModifiedDate ? file.lastModifiedDate.toLocaleDateString() :\n",
              "                                    'n/a'} - `));\n",
              "    const percent = span('0% done');\n",
              "    li.appendChild(percent);\n",
              "\n",
              "    outputElement.appendChild(li);\n",
              "\n",
              "    const fileDataPromise = new Promise((resolve) => {\n",
              "      const reader = new FileReader();\n",
              "      reader.onload = (e) => {\n",
              "        resolve(e.target.result);\n",
              "      };\n",
              "      reader.readAsArrayBuffer(file);\n",
              "    });\n",
              "    // Wait for the data to be ready.\n",
              "    let fileData = yield {\n",
              "      promise: fileDataPromise,\n",
              "      response: {\n",
              "        action: 'continue',\n",
              "      }\n",
              "    };\n",
              "\n",
              "    // Use a chunked sending to avoid message size limits. See b/62115660.\n",
              "    let position = 0;\n",
              "    do {\n",
              "      const length = Math.min(fileData.byteLength - position, MAX_PAYLOAD_SIZE);\n",
              "      const chunk = new Uint8Array(fileData, position, length);\n",
              "      position += length;\n",
              "\n",
              "      const base64 = btoa(String.fromCharCode.apply(null, chunk));\n",
              "      yield {\n",
              "        response: {\n",
              "          action: 'append',\n",
              "          file: file.name,\n",
              "          data: base64,\n",
              "        },\n",
              "      };\n",
              "\n",
              "      let percentDone = fileData.byteLength === 0 ?\n",
              "          100 :\n",
              "          Math.round((position / fileData.byteLength) * 100);\n",
              "      percent.textContent = `${percentDone}% done`;\n",
              "\n",
              "    } while (position < fileData.byteLength);\n",
              "  }\n",
              "\n",
              "  // All done.\n",
              "  yield {\n",
              "    response: {\n",
              "      action: 'complete',\n",
              "    }\n",
              "  };\n",
              "}\n",
              "\n",
              "scope.google = scope.google || {};\n",
              "scope.google.colab = scope.google.colab || {};\n",
              "scope.google.colab._files = {\n",
              "  _uploadFiles,\n",
              "  _uploadFilesContinue,\n",
              "};\n",
              "})(self);\n",
              "</script> "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Saving page_url.txt to page_url.txt\n"
          ]
        }
      ],
      "source": [
        "from google.colab import files\n",
        "\n",
        "uploaded = files.upload()"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import requests\n",
        "from bs4 import BeautifulSoup\n",
        "\n",
        "url_file = open('page_url.txt','r')\n",
        "headers = {\n",
        "    'User-Agent': 'Mozilla/5.0 (Windows NT 6.1) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/41.0.2228.0 Safari/537.36'\n",
        "}\n",
        "\n",
        "c = 1\n",
        "with open('products_urls.txt', 'w') as f:\n",
        "  for i in url_file:\n",
        "    url = i\n",
        "    print(\"Link\",c,\"scanned!!\")\n",
        "    c+=1\n",
        "    page = requests.get(url, headers = headers)\n",
        "\n",
        "    htmlContent = page.content\n",
        "    soup = BeautifulSoup(htmlContent,'html.parser')\n",
        "\n",
        "    links = soup.find_all('a',{'class':'a-link-normal s-underline-text s-underline-link-text s-link-style'})\n",
        "    for i in links:\n",
        "      if(i.get('href')[-7:-2]=='Revie'):\n",
        "        url = 'https://www.amazon.in'+i.get('href')[:-16]\n",
        "        f.write(url)\n",
        "        f.write('\\n')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "io8Ms48KPyUm",
        "outputId": "e920ed47-700c-480f-92db-b09616b1e280"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Link 1 scanned!!\n",
            "Link 2 scanned!!\n",
            "Link 3 scanned!!\n",
            "Link 4 scanned!!\n",
            "Link 5 scanned!!\n",
            "Link 6 scanned!!\n",
            "Link 7 scanned!!\n",
            "Link 8 scanned!!\n",
            "Link 9 scanned!!\n",
            "Link 10 scanned!!\n",
            "Link 11 scanned!!\n",
            "Link 12 scanned!!\n",
            "Link 13 scanned!!\n",
            "Link 14 scanned!!\n",
            "Link 15 scanned!!\n",
            "Link 16 scanned!!\n",
            "Link 17 scanned!!\n",
            "Link 18 scanned!!\n",
            "Link 19 scanned!!\n",
            "Link 20 scanned!!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def product_name(soup):\n",
        "  title = soup.find(\"span\", attrs={\"id\":'productTitle'})\n",
        "  if title is not None:\n",
        "    ret = title.string.strip()\n",
        "    return ret\n",
        "\n",
        "  return \"\"\n",
        "\n",
        "def product_price(soup):\n",
        "  price = soup.find(\"span\", attrs={\"class\":'a-price-whole'})\n",
        "  if price is not None:\n",
        "    ret = 'Rs. '+price.text.strip()[:-1]\n",
        "    return ret\n",
        "  \n",
        "  return \"\"\n",
        "\n",
        "def product_rating(soup):\n",
        "  rating = soup.find(\"i\",attrs={\"class\":'a-icon-star'}).find('span')\n",
        "  if rating is not None:\n",
        "    ret = rating.text\n",
        "    return ret\n",
        "\n",
        "  return \"\"\n",
        "\n",
        "def product_reviews(soup):\n",
        "  reviews = soup.find(\"span\",attrs={\"id\":'acrCustomerReviewText'})\n",
        "  if reviews is not None:\n",
        "    ret = reviews.text.split()[0]\n",
        "    return ret\n",
        "\n",
        "  return \"\""
      ],
      "metadata": {
        "id": "T8AfZQ_USCx7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import csv  \n",
        "\n",
        "header = ['Product Title', 'Price', 'Rating', 'Reviews','Product URL']\n",
        "\n",
        "file = open('products_urls.txt','r')\n",
        "with open('products_data.csv', 'w') as f:\n",
        "  c = 0\n",
        "  for i in file:\n",
        "    c+=1\n",
        "    print(\"Product\",c)\n",
        "    product_url = i\n",
        "    page = requests.get(product_url, headers = headers)\n",
        "    htmlContent = page.content\n",
        "    soup = BeautifulSoup(htmlContent,'html.parser')\n",
        "\n",
        "    name = product_name(soup)\n",
        "    price = product_price(soup)\n",
        "    rating = product_rating(soup)\n",
        "    reviews = product_reviews(soup)\n",
        "    data = [name, price, rating, reviews, product_url]\n",
        "    writer = csv.writer(f)\n",
        "    if(c==1):\n",
        "      writer.writerow(header)\n",
        "    \n",
        "    writer.writerow(data)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uthbYJ7bSWWZ",
        "outputId": "8bf3d5ef-33ad-45be-ad4f-4026dce86bfa"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Product 1\n",
            "Product 2\n",
            "Product 3\n",
            "Product 4\n",
            "Product 5\n",
            "Product 6\n",
            "Product 7\n",
            "Product 8\n",
            "Product 9\n",
            "Product 10\n",
            "Product 11\n",
            "Product 12\n",
            "Product 13\n",
            "Product 14\n",
            "Product 15\n",
            "Product 16\n",
            "Product 17\n",
            "Product 18\n",
            "Product 19\n",
            "Product 20\n",
            "Product 21\n",
            "Product 22\n",
            "Product 23\n",
            "Product 24\n",
            "Product 25\n",
            "Product 26\n",
            "Product 27\n",
            "Product 28\n",
            "Product 29\n",
            "Product 30\n",
            "Product 31\n",
            "Product 32\n",
            "Product 33\n",
            "Product 34\n",
            "Product 35\n",
            "Product 36\n",
            "Product 37\n",
            "Product 38\n",
            "Product 39\n",
            "Product 40\n",
            "Product 41\n",
            "Product 42\n",
            "Product 43\n",
            "Product 44\n",
            "Product 45\n",
            "Product 46\n",
            "Product 47\n",
            "Product 48\n",
            "Product 49\n",
            "Product 50\n",
            "Product 51\n",
            "Product 52\n",
            "Product 53\n",
            "Product 54\n",
            "Product 55\n",
            "Product 56\n",
            "Product 57\n",
            "Product 58\n",
            "Product 59\n",
            "Product 60\n",
            "Product 61\n",
            "Product 62\n",
            "Product 63\n",
            "Product 64\n",
            "Product 65\n",
            "Product 66\n",
            "Product 67\n",
            "Product 68\n",
            "Product 69\n",
            "Product 70\n",
            "Product 71\n",
            "Product 72\n",
            "Product 73\n",
            "Product 74\n",
            "Product 75\n",
            "Product 76\n",
            "Product 77\n",
            "Product 78\n",
            "Product 79\n",
            "Product 80\n",
            "Product 81\n",
            "Product 82\n",
            "Product 83\n",
            "Product 84\n",
            "Product 85\n",
            "Product 86\n",
            "Product 87\n",
            "Product 88\n",
            "Product 89\n",
            "Product 90\n",
            "Product 91\n",
            "Product 92\n",
            "Product 93\n",
            "Product 94\n",
            "Product 95\n",
            "Product 96\n",
            "Product 97\n",
            "Product 98\n",
            "Product 99\n",
            "Product 100\n",
            "Product 101\n",
            "Product 102\n",
            "Product 103\n",
            "Product 104\n",
            "Product 105\n",
            "Product 106\n",
            "Product 107\n",
            "Product 108\n",
            "Product 109\n",
            "Product 110\n",
            "Product 111\n",
            "Product 112\n",
            "Product 113\n",
            "Product 114\n",
            "Product 115\n",
            "Product 116\n",
            "Product 117\n",
            "Product 118\n",
            "Product 119\n",
            "Product 120\n",
            "Product 121\n",
            "Product 122\n",
            "Product 123\n",
            "Product 124\n",
            "Product 125\n",
            "Product 126\n",
            "Product 127\n",
            "Product 128\n",
            "Product 129\n",
            "Product 130\n",
            "Product 131\n",
            "Product 132\n",
            "Product 133\n",
            "Product 134\n",
            "Product 135\n",
            "Product 136\n",
            "Product 137\n",
            "Product 138\n",
            "Product 139\n",
            "Product 140\n",
            "Product 141\n",
            "Product 142\n",
            "Product 143\n",
            "Product 144\n",
            "Product 145\n",
            "Product 146\n",
            "Product 147\n",
            "Product 148\n",
            "Product 149\n",
            "Product 150\n",
            "Product 151\n",
            "Product 152\n",
            "Product 153\n",
            "Product 154\n",
            "Product 155\n",
            "Product 156\n",
            "Product 157\n",
            "Product 158\n",
            "Product 159\n",
            "Product 160\n",
            "Product 161\n",
            "Product 162\n",
            "Product 163\n",
            "Product 164\n",
            "Product 165\n",
            "Product 166\n",
            "Product 167\n"
          ]
        }
      ]
    }
  ]
}